# ğŸ–¼ï¸ Image Recognition System

**Component:** Handicraft image recognition and similarity search  
**Team Member:** Rajapaksha D N  
**Status:** ğŸŸ¡ In Progress (MVP)

## Overview

This system allows users to upload a photo of a handicraft item and find similar products from the LAKARCADE catalog. The MVP uses CLIP (Contrastive Language-Image Pre-Training) embeddings for semantic similarity search.

## ğŸ¯ Current Status: MVP Phase 1

**What's Working:**
- âœ… Image upload and preprocessing
- âœ… CLIP embedding extraction
- âœ… FAISS vector database for fast similarity search
- âœ… REST API with FastAPI
- âœ… Basic similarity scoring

**Next Steps:**
- ğŸ”² Add real product data indexing
- ğŸ”² Implement per-feature scoring (shape, color, texture, pattern)
- ğŸ”² Add PostgreSQL for product metadata
- ğŸ”² Background removal/preprocessing
- ğŸ”² Graph database (Neo4j) for related items

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Installation

1. **Navigate to the image-recognition-system directory:**
   ```bash
   cd image-recognition-system
   ```

2. **Create a virtual environment (recommended):**
   ```bash
   python -m venv venv
   
   # On Windows:
   venv\Scripts\activate
   
   # On Mac/Linux:
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

   **Note:** This will download the CLIP model (~350MB) on first run. The first startup may take a few minutes.

### Running the Server

```bash
python -m app.main
```

Or using uvicorn directly:
```bash
uvicorn app.main:app --reload --port 8000
```

The API will be available at: `http://localhost:8000`

### API Documentation

Once the server is running, visit:
- **Interactive API Docs:** http://localhost:8000/docs
- **Alternative Docs:** http://localhost:8000/redoc

## ğŸ“¡ API Endpoints

### 1. Health Check
```http
GET /health
```

### 2. Search Similar Products
```http
POST /api/v1/search
Content-Type: multipart/form-data

Body: file (image file)
```

**Example using curl:**
```bash
curl -X POST "http://localhost:8000/api/v1/search" \
  -F "file=@path/to/your/image.jpg"
```

**Response:**
```json
{
  "query_id": "image.jpg",
  "total_matches": 5,
  "results": [
    {
      "product_id": "MASK_001",
      "title": "Traditional Sanni Mask",
      "description": "Hand-carved wooden mask...",
      "similarity_score": 0.85,
      "rank": 1
    },
    ...
  ]
}
```

### 3. Add Product to Index
```http
POST /api/v1/upload-product
Content-Type: multipart/form-data

Body:
  - file (image file)
  - product_id (optional)
  - title (optional)
  - description (optional)
```

## ğŸ“ Project Structure

```
image-recognition-system/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ search.py           # Pydantic models
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ image_processor.py  # Image preprocessing
â”‚       â”œâ”€â”€ clip_encoder.py     # CLIP embedding extraction
â”‚       â””â”€â”€ vector_store.py     # FAISS vector database
â”œâ”€â”€ data/                       # Generated data (gitignored)
â”‚   â”œâ”€â”€ faiss_index.idx         # FAISS index file
â”‚   â””â”€â”€ metadata.pkl            # Product metadata
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## ğŸ§ª Testing with Sample Data

The system automatically creates 5 sample products on first run (with random embeddings). To test:

1. Start the server
2. Use the `/api/v1/search` endpoint to upload any image
3. You'll get back 5 sample results (with random similarity scores)

**To use real product data:**
1. Prepare your product images
2. Use the `/api/v1/upload-product` endpoint to add each product
3. Or modify `vector_store.py` to load products from a directory

## ğŸ”§ Configuration

### CLIP Model
Default model: `ViT-B/32` (faster, smaller)  
To use a larger model, edit `app/services/clip_encoder.py`:
```python
clip_encoder = CLIPEncoder(model_name="ViT-L/14")  # Better accuracy, slower
```

### Image Preprocessing
Default target size: 384px (shorter edge)  
Edit `app/services/image_processor.py` to change:
```python
image_processor = ImageProcessor(target_size=512)
```

## ğŸ› Troubleshooting

### "CUDA out of memory" or slow performance
- The system automatically uses CPU if CUDA is not available
- To force CPU, edit `app/services/clip_encoder.py` and set `device="cpu"`

### "No module named 'clip'"
- Make sure you installed requirements: `pip install -r requirements.txt`
- The `clip-by-openai` package should install automatically

### Index not found
- This is normal on first run - a new index will be created
- Sample products will be automatically added

## ğŸ“š Next Development Steps

1. **Add Real Product Data**
   - Create script to batch-load product images
   - Store product metadata in PostgreSQL

2. **Enhance Feature Extraction**
   - Add shape CNN (EfficientNet/ResNet)
   - Add color histogram extraction
   - Add texture analysis (LBP)
   - Add pattern descriptors (SIFT/ORB)

3. **Improve Similarity Scoring**
   - Implement per-feature scoring
   - Weighted fusion of multiple features
   - Re-ranking based on business rules

4. **Add Graph Database**
   - Store product relationships in Neo4j
   - Traverse graph for related items

5. **Production Features**
   - Background removal
   - Object detection
   - Material classification
   - User feedback loop
   - Monitoring and analytics

## ğŸ“ Notes

- **For Academic Use:** This is a research project for SLIIT final year
- **Performance:** MVP focuses on functionality over optimization
- **Scalability:** FAISS can handle millions of vectors efficiently
- **GPU:** Optional but recommended for faster inference

## ğŸ“ Support

For questions or issues, contact the team or refer to the main project README.
